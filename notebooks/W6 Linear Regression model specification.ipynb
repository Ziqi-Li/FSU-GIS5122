{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression - model specification\n",
    "This notebook demostrates:\n",
    "\n",
    "0. Correctly specified model (baseline)\n",
    "1. Under-specified model\n",
    "    - Uncorrelated predictors\n",
    "    - Correlated predictors\n",
    "2. Over-specified model\n",
    "    - Perfect multi-colinearity\n",
    "    - Varying degrees of Multi-colinearity\n",
    "    - Including non related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Correctly specified model (baseline)\n",
    "\n",
    "- We randomly generate 100 uncorrelated X1 and X2 following a normal distirbution.\n",
    "\n",
    "- We speficy a true regression line: $y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- We correctly include X1 and X2 in our regression model: y ~ X1 + X2 (with intercept)\n",
    "\n",
    "- We fit 1000 such regression models and check for biasedness and preciseness of the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    X1 = np.random.randn(100)\n",
    "    X2 = np.random.randn(100)\n",
    "    \n",
    "    e = np.random.randn(100)\n",
    "    y = 3 + 2*X1 + 4*X2 + e\n",
    "    X = sm.add_constant(np.column_stack([X1,X2]))\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of estimates: [2.99693107 1.9989116  3.99801653]\n",
      "SE of estimates: [0.09907705 0.10185332 0.10522559]\n"
     ]
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "print(\"Average of estimates:\", np.mean(np.array(estimates),axis=0))\n",
    "print(\"SE of estimates:\", np.std(np.array(estimates),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Under-specified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncorrelated predictors (#1)\n",
    "- We randomly generate 100 uncorrelated X1 and X2 following a normal distirbution.\n",
    "\n",
    "- We speficy a true regression line: $y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- We only include X1 in our regression model: y ~ X1 (with intercept)\n",
    "\n",
    "- We fit 1000 such regression models and check for biasedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    means = [4,2]\n",
    "    cov = [[1,0], [0,1]]\n",
    "    X = np.random.multivariate_normal(means,cov,100)\n",
    "\n",
    "    e = np.random.randn(100)\n",
    "    y = 3 + 2*X[:,0] + 4*X[:,1] + e\n",
    "    X = sm.add_constant(X[:,0])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of estimates: [11.04517657  1.99440733]\n",
      "SE of estimates: [1.65451365 0.40479627]\n"
     ]
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "print(\"Average of estimates:\", np.mean(np.array(estimates),axis=0))\n",
    "\n",
    "print(\"SE of estimates:\", np.std(np.array(estimates),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the intercept estimate is **biased**, and the coefficient for b1 is **unbiased**. The SE of the estimates are much higher than that in a correctly specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated predictors (#2)\n",
    "- We randomly generate 100 correlated X1 and X2 following a bi-variate normal distirbution (so X1 and X2 are having a correlation coefficient of 0.4).\n",
    "\n",
    "- We speficy a true regression line: $y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- We only include X1 in our regression model: y ~ X1 (with intercept)\n",
    "\n",
    "- We fit 1000 such regression models and check for biasedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    means = [4,2]\n",
    "    cov = [[1,0.4], [0.4,1]]\n",
    "    X = np.random.multivariate_normal(means,cov,100)\n",
    "\n",
    "    e = np.random.randn(100)\n",
    "    y = 3 + 2*X[:,0] + 4*X[:,1] + e\n",
    "    X = sm.add_constant(X[:,0])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.61173289, 3.59313288])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "np.mean(np.array(estimates),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.56633713, 0.38443653])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "np.std(np.array(estimates),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the intercept estimate is **biased**, and the coefficient for b1 is also **biased** from its true value of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: when predictors are correlated, omitting one will make other estimates biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Over-specified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfect multicolinearity (#1)\n",
    "- We randomly generate 100 data points for X1 following a normal distribution.\n",
    "- We set X2 = 1 - X1\n",
    "\n",
    "- We speficy a true regression line: $y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- We only fit the regression model as: y ~ X1 + X2 (with intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.randn(100)\n",
    "X2 = 1 - X1\n",
    "e = np.random.randn(100)\n",
    "\n",
    "y = 3 + 2*X1 + 4*X2 + e\n",
    "\n",
    "X = sm.add_constant(np.column_stack([X1,X2]))\n",
    "\n",
    "model = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>1.93e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:53:29</td>     <th>  Log-Likelihood:    </th> <td> -139.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   282.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   287.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.9815</td> <td>    0.074</td> <td>   54.019</td> <td> 0.000</td> <td>    3.835</td> <td>    4.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.9864</td> <td>    0.072</td> <td>   13.706</td> <td> 0.000</td> <td>    0.844</td> <td>    1.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    2.9951</td> <td>    0.045</td> <td>   66.782</td> <td> 0.000</td> <td>    2.906</td> <td>    3.084</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.927</td> <th>  Durbin-Watson:     </th> <td>   2.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.381</td> <th>  Jarque-Bera (JB):  </th> <td>   1.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.262</td> <th>  Prob(JB):          </th> <td>   0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.577</td> <th>  Cond. No.          </th> <td>4.08e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.94e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.821   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.820   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     450.8   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 Feb 2024 & \\textbf{  Prob (F-statistic):} &  1.93e-38   \\\\\n",
       "\\textbf{Time:}             &     14:53:29     & \\textbf{  Log-Likelihood:    } &   -139.36   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     282.7   \\\\\n",
       "\\textbf{Df Residuals:}     &          98      & \\textbf{  BIC:               } &     287.9   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       3.9815  &        0.074     &    54.019  &         0.000        &        3.835    &        4.128     \\\\\n",
       "\\textbf{x1}    &       0.9864  &        0.072     &    13.706  &         0.000        &        0.844    &        1.129     \\\\\n",
       "\\textbf{x2}    &       2.9951  &        0.045     &    66.782  &         0.000        &        2.906    &        3.084     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.927 & \\textbf{  Durbin-Watson:     } &    2.079  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.381 & \\textbf{  Jarque-Bera (JB):  } &    1.886  \\\\\n",
       "\\textbf{Skew:}          &  0.262 & \\textbf{  Prob(JB):          } &    0.389  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.577 & \\textbf{  Cond. No.          } & 4.08e+15  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.94e-29. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.821\n",
       "Model:                            OLS   Adj. R-squared:                  0.820\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Mon, 12 Feb 2024   Prob (F-statistic):           1.93e-38\n",
       "Time:                        14:53:29   Log-Likelihood:                -139.36\n",
       "No. Observations:                 100   AIC:                             282.7\n",
       "Df Residuals:                      98   BIC:                             287.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.9815      0.074     54.019      0.000       3.835       4.128\n",
       "x1             0.9864      0.072     13.706      0.000       0.844       1.129\n",
       "x2             2.9951      0.045     66.782      0.000       2.906       3.084\n",
       "==============================================================================\n",
       "Omnibus:                        1.927   Durbin-Watson:                   2.079\n",
       "Prob(Omnibus):                  0.381   Jarque-Bera (JB):                1.886\n",
       "Skew:                           0.262   Prob(JB):                        0.389\n",
       "Kurtosis:                       2.577   Cond. No.                     4.08e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.94e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Multicolinearity (#2)\n",
    "- We randomly generate 100 correlated X1 and X2 following a bi-variate normal distirbution and let X1 and X2 have different degree of correlation (0, 0.3, 0.6, 0.9, 0.95, and 0.99).\n",
    "\n",
    "- We speficy a true regression line: $y$ = 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- We include X1 and X2 in our regression model: y ~ X1 + X2 (no intercept, for simplicity)\n",
    "\n",
    "- For each pre-set correlation value, we repeat 1000 times to generate the sampling distirbution of regression estimates.\n",
    "- Plot the sampling distirbutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to return the sampling distribution of regression coefficients \n",
    "# based on different degree of correlation between X1 and X2\n",
    "def simulation_multi_colinearity(cor):\n",
    "    params = []\n",
    "    for i in range(1000):\n",
    "        means = [4,2]\n",
    "        cov = [[1,cor], [cor,1]]\n",
    "        X = np.random.multivariate_normal(means,cov,100)\n",
    "        e = np.random.randn(100)*2\n",
    "        y = 2*X[:,0] + 4*X[:,1] + e\n",
    "        model = sm.OLS(y,X).fit()\n",
    "        params.append(model.params)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dist_0 = simulation_multi_colinearity(0)\n",
    "sampling_dist_0_3 = simulation_multi_colinearity(0.3)\n",
    "sampling_dist_0_6 = simulation_multi_colinearity(0.6)\n",
    "sampling_dist_0_9 = simulation_multi_colinearity(0.9)\n",
    "sampling_dist_0_95 = simulation_multi_colinearity(0.95)\n",
    "sampling_dist_0_99 = simulation_multi_colinearity(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE of estimates when X1 and X2 have a cor of 0: [0.09774962 0.17829866]\n",
      "SE of estimates when X1 and X2 have a cor of 0.3: [0.11897213 0.21516405]\n",
      "SE of estimates when X1 and X2 have a cor of 0.6: [0.13283715 0.24456713]\n",
      "SE of estimates when X1 and X2 have a cor of 0.9: [0.18710183 0.34713535]\n",
      "SE of estimates when X1 and X2 have a cor of 0.95: [0.19926059 0.36769283]\n",
      "SE of estimates when X1 and X2 have a cor of 0.99: [0.23572081 0.43517237]\n"
     ]
    }
   ],
   "source": [
    "print(\"SE of estimates when X1 and X2 have a cor of 0:\", np.std(sampling_dist_0,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.3:\", np.std(sampling_dist_0_3,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.6:\", np.std(sampling_dist_0_6,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.9:\", np.std(sampling_dist_0_9,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.95:\", np.std(sampling_dist_0_95,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.99:\", np.std(sampling_dist_0_99,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of estimates when X1 and X2 have a cor of 0: [1.99815907 4.00067393]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.3: [2.00283493 3.99499812]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.6: [2.00121313 4.00266588]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.9: [2.01198014 3.97377536]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.95: [2.00067449 3.99208516]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.99: [2.00075003 3.99593505]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of estimates when X1 and X2 have a cor of 0:\", np.mean(sampling_dist_0,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.3:\", np.mean(sampling_dist_0_3,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.6:\", np.mean(sampling_dist_0_6,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.9:\", np.mean(sampling_dist_0_9,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.95:\", np.mean(sampling_dist_0_95,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.99:\", np.mean(sampling_dist_0_99,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that, with varying degrees of correlation between the two predictors in the model, the regression coefficients are still **unbiased**, but the standard error of the estimates are **inflated** based on the degree of the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding non-related predictors (#2)\n",
    "- We randomly generate 100 data points for X1, X2, and X3 following a normal distribution.\n",
    "\n",
    "- We speficy a true regression line: $y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- We  include X1, X2, and X3in our regression model: y ~ X1 (with intercept). Here X3 should not be in the model, but included.\n",
    "\n",
    "- We fit 1000 such regression models and check for biasedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    X1 = np.random.randn(100)\n",
    "    X2 = np.random.randn(100)\n",
    "    X3 = np.random.randn(100)\n",
    "    e = np.random.randn(100)\n",
    "\n",
    "    y = 3 + 2*X1 + 4*X2 + e\n",
    "\n",
    "    X = sm.add_constant(np.column_stack([X1,X2,X3]))\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of estimates: [ 3.00154667e+00  1.99827735e+00  3.99297478e+00 -3.24848139e-03]\n",
      "SE of estimates: [0.10063326 0.10192471 0.10255253 0.10575763]\n"
     ]
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "print(\"Average of estimates:\", np.mean(np.array(estimates),axis=0))\n",
    "print(\"SE of estimates:\", np.std(np.array(estimates),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the estimates of X1 and X2 are **unbiased**, and the standard errors are also quite small. The estimate for X3 is nearly **zero**, and if we check one model out of the 1000, we find the estimate is not statistically significant. In this sense, including non-related random data into the model does not do  much harm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   552.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>2.17e-60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:53:30</td>     <th>  Log-Likelihood:    </th> <td> -138.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   285.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   295.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.9756</td> <td>    0.102</td> <td>   29.294</td> <td> 0.000</td> <td>    2.774</td> <td>    3.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.0007</td> <td>    0.119</td> <td>   16.877</td> <td> 0.000</td> <td>    1.765</td> <td>    2.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.9751</td> <td>    0.099</td> <td>   40.036</td> <td> 0.000</td> <td>    3.778</td> <td>    4.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1522</td> <td>    0.100</td> <td>   -1.520</td> <td> 0.132</td> <td>   -0.351</td> <td>    0.047</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.052</td> <th>  Durbin-Watson:     </th> <td>   1.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.217</td> <th>  Jarque-Bera (JB):  </th> <td>   1.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.041</td> <th>  Prob(JB):          </th> <td>   0.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.337</td> <th>  Cond. No.          </th> <td>    1.50</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.945   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.944   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     552.2   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 Feb 2024 & \\textbf{  Prob (F-statistic):} &  2.17e-60   \\\\\n",
       "\\textbf{Time:}             &     14:53:30     & \\textbf{  Log-Likelihood:    } &   -138.60   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     285.2   \\\\\n",
       "\\textbf{Df Residuals:}     &          96      & \\textbf{  BIC:               } &     295.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.9756  &        0.102     &    29.294  &         0.000        &        2.774    &        3.177     \\\\\n",
       "\\textbf{x1}    &       2.0007  &        0.119     &    16.877  &         0.000        &        1.765    &        2.236     \\\\\n",
       "\\textbf{x2}    &       3.9751  &        0.099     &    40.036  &         0.000        &        3.778    &        4.172     \\\\\n",
       "\\textbf{x3}    &      -0.1522  &        0.100     &    -1.520  &         0.132        &       -0.351    &        0.047     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.052 & \\textbf{  Durbin-Watson:     } &    1.835  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.217 & \\textbf{  Jarque-Bera (JB):  } &    1.860  \\\\\n",
       "\\textbf{Skew:}          & -0.041 & \\textbf{  Prob(JB):          } &    0.395  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.337 & \\textbf{  Cond. No.          } &     1.50  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.945\n",
       "Model:                            OLS   Adj. R-squared:                  0.944\n",
       "Method:                 Least Squares   F-statistic:                     552.2\n",
       "Date:                Mon, 12 Feb 2024   Prob (F-statistic):           2.17e-60\n",
       "Time:                        14:53:30   Log-Likelihood:                -138.60\n",
       "No. Observations:                 100   AIC:                             285.2\n",
       "Df Residuals:                      96   BIC:                             295.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9756      0.102     29.294      0.000       2.774       3.177\n",
       "x1             2.0007      0.119     16.877      0.000       1.765       2.236\n",
       "x2             3.9751      0.099     40.036      0.000       3.778       4.172\n",
       "x3            -0.1522      0.100     -1.520      0.132      -0.351       0.047\n",
       "==============================================================================\n",
       "Omnibus:                        3.052   Durbin-Watson:                   1.835\n",
       "Prob(Omnibus):                  0.217   Jarque-Bera (JB):                1.860\n",
       "Skew:                          -0.041   Prob(JB):                        0.395\n",
       "Kurtosis:                       2.337   Cond. No.                         1.50\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
